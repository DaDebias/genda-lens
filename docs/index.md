----------

![Screenshot](img/logo.png){ align=right, width="500"}

A package for investigating gender bias in Danish language models within the following domains:  

* **Language Modeling** (for pre-trained models)  

* **Coreference Resolution** (for coref. models)  

* **Named Entity Recognition** (for NER models)  

----------

If you want to test either a pre-trained model, a coref. model or a NER model, you can read more about each of these three types of tests in the User Guide.  

Here you can also find a section on the *definitions* of harm, gender and bias that we adopt in the GenDa Lens package. 

:hugging: Note that for NER and Language Modeling, the GenDa Lens evaluator is integrated with Hugging Face.

The package can be run on Python >=3.9 due to the dependency on the newest version of the DaCy library (2.7.0). 
